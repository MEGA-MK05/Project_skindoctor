import numpy as np
import cv2
from PIL import ImageFont, ImageDraw, Image
import time
import os
import platform
import ollama
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic, QuantType
import psutil
import threading
import queue

# --- ì„¤ì • ---
CAPTURE_INTERVAL = 1  # ìº¡ì²˜ ê°„ê²© (ì´ˆ)
CAPTURE_COUNT = 5     # ìº¡ì²˜ íšŸìˆ˜
CAPTURE_FOLDER = "captures" # ìº¡ì²˜ ì´ë¯¸ì§€ ì €ì¥ í´ë”
OLLAMA_MODEL = "gemma3:1b" # ì‚¬ìš©í•  Ollama ëª¨ë¸

# ì¹´ë©”ë¼ ì„¤ì • (ë¼ì¦ˆë² ë¦¬ íŒŒì´ 5 ìµœì í™”ë¥¼ ìœ„í•´ ì¡°ì • ê°€ëŠ¥)
CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480
CAMERA_FPS = 15

PREDICTION_SMOOTHING_WINDOW_SIZE = 5 # ì˜ˆì¸¡ ê²°ê³¼ ìŠ¤ë¬´ë”©ì„ ìœ„í•œ í”„ë ˆì„ ìˆ˜ (5~10 ì •ë„ ê¶Œì¥)
DISPLAY_UPDATE_INTERVAL_MS = 400 # í™”ë©´ì— í‘œì‹œë˜ëŠ” ì˜ˆì¸¡ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì£¼ê¸° (ë°€ë¦¬ì´ˆ)

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •

ONNX_MODEL_PATH = "./model/skin_model.onnx"
ONNX_OPTIMIZED_PATH = "./model/skin_model_quantized.onnx" # ìì˜ì ìœ¼ë¡œ ë°”ê¿”ì„œ ìµœì í™” ëª¨ë¸ ê²½ë¡œ ì„¤ì •
ONNX_QUANTIZED_PATH = "./model/skin_model_quantized.onnx"
TFLITE_MODEL_PATH = "./model/skin_model_quantized.tflite"

# --- OSë³„ ì„¤ì • í•¨ìˆ˜ ---
def get_system_font_path():
    """OSë³„ ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ ë°˜í™˜"""
    system = platform.system()
    
    if system == "Windows":
        return "C:/Windows/Fonts/malgun.ttf"
    elif system == "Linux":
        # Ubuntu/Debian ê³„ì—´
        linux_fonts = [
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
            "/usr/share/fonts/TTF/NanumGothic.ttf",  # Arch Linux
            "/System/Library/Fonts/Helvetica.ttc"    # macOS backup
        ]
        for font in linux_fonts:
            if os.path.exists(font):
                return font
    elif system == "Darwin":  # macOS
        return "/System/Library/Fonts/AppleGothic.ttf"
    
    # ê¸°ë³¸ê°’ (í°íŠ¸ê°€ ì—†ëŠ” ê²½ìš°)
    return None

def get_backup_model_path():
    """ë°±ì—… H5 ëª¨ë¸ ê²½ë¡œ ë°˜í™˜ (OS ë¬´ê´€)"""
    possible_paths = [
        "./model/jaehong_skin_model.h5",  # ìƒëŒ€ ê²½ë¡œ (ìš°ì„ )
        "../pth/jaehong_skin_model.h5",   # ìƒìœ„ í´ë”
        "./jaehong_skin_model.h5",       # í˜„ì¬ í´ë”
        "C:/Users/kccistc/project/pth/jaehong_skin_model.h5",  # Windows ì ˆëŒ€ ê²½ë¡œ
        "/home/kccistc/project/pth/jaehong_skin_model.h5"       # Linux ì ˆëŒ€ ê²½ë¡œ
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None

# --- í´ë˜ìŠ¤ ë° ëª¨ë¸ ì„¤ì • ---
# í´ë˜ìŠ¤ëª… (7ê°œ í´ë˜ìŠ¤)
class_names_kr = [
    'ê¸°ì €ì„¸í¬ì•”',
    'í‘œí”¼ë‚­ì¢…',
    'í˜ˆê´€ì¢…',
    'ë¹„ë¦½ì¢…',
    'ì •ìƒí”¼ë¶€',
    'í¸í‰ì„¸í¬ì•”',
    'ì‚¬ë§ˆê·€'
]

# --- ìµœì í™”ëœ ONNX ëª¨ë¸ í´ë˜ìŠ¤ ---
class OptimizedONNXModel:
    def __init__(self, model_path, optimization_level="all", use_gpu=False):
        """
        ìµœì í™”ëœ ONNX ëª¨ë¸ ë¡œë“œ
        
        Args:
            model_path: ëª¨ë¸ ê²½ë¡œ
            optimization_level: ìµœì í™” ë ˆë²¨ ("disable", "basic", "extended", "all")
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
        """
        self.model_path = model_path
        self.optimization_level = optimization_level
        self.use_gpu = use_gpu
        
        # ì„¸ì…˜ ì˜µì…˜ ì„¤ì •
        self.session_options = ort.SessionOptions()
        
        # ìµœì í™” ë ˆë²¨ ì„¤ì •
        if optimization_level == "disable":
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL
        elif optimization_level == "basic":
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_BASIC
        elif optimization_level == "extended":
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED
        else:  # "all"
            self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
        cpu_count = psutil.cpu_count(logical=False)
        self.session_options.intra_op_num_threads = cpu_count
        self.session_options.inter_op_num_threads = cpu_count
        
        # ë©”ëª¨ë¦¬ íŒ¨í„´ ìµœì í™”
        self.session_options.enable_mem_pattern = True
        self.session_options.enable_cpu_mem_arena = True
        
        # ì‹¤í–‰ ì œê³µì ì„¤ì •
        providers = self._get_providers()
        
        try:
            # ONNX ì„¸ì…˜ ìƒì„±
            self.session = ort.InferenceSession(
                model_path, 
                sess_options=self.session_options,
                providers=providers
            )
            
            # ì…ì¶œë ¥ ì •ë³´
            self.input_name = self.session.get_inputs()[0].name
            self.output_name = self.session.get_outputs()[0].name
            
            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            print(f"âœ… ìµœì í™”ëœ ONNX ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
            print(f"   ğŸ”§ ìµœì í™” ë ˆë²¨: {optimization_level}")
            print(f"   ğŸ§µ Intra-op threads: {self.session_options.intra_op_num_threads}")
            print(f"   ğŸ§µ Inter-op threads: {self.session_options.inter_op_num_threads}")
            print(f"   ğŸ’» ì‚¬ìš© ì¤‘ì¸ Providers: {self.session.get_providers()}")
            
        except Exception as e:
            print(f"âŒ ìµœì í™”ëœ ONNX ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_providers(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í–‰ ì œê³µì ë°˜í™˜"""
        providers = []
        available_providers = ort.get_available_providers()
        system = platform.system()
        
        # GPU ì‚¬ìš© ì‹œë„
        if self.use_gpu:
            # DirectML (Windowsë§Œ)
            if system == "Windows" and 'DmlExecutionProvider' in available_providers:
                providers.append('DmlExecutionProvider')
                print("ğŸ® DirectML Provider ì‚¬ìš© (Windows GPU)")
            
            # CUDA (NVIDIA - ëª¨ë“  OS)
            if 'CUDAExecutionProvider' in available_providers:
                providers.append('CUDAExecutionProvider')
                print("ğŸš€ CUDA Provider ì‚¬ìš© (NVIDIA GPU)")
            
            # ROCm (AMD - Linux)
            if system == "Linux" and 'ROCMExecutionProvider' in available_providers:
                providers.append('ROCMExecutionProvider')
                print("ğŸ”¥ ROCm Provider ì‚¬ìš© (AMD GPU)")
            
            # OpenVINO (Intel - ëª¨ë“  OS)
            if 'OpenVINOExecutionProvider' in available_providers:
                providers.append('OpenVINOExecutionProvider')
                print("âš¡ OpenVINO Provider ì‚¬ìš© (Intel GPU)")
            
            # TensorRT (NVIDIA - Linux ì£¼ë¡œ)
            if 'TensorrtExecutionProvider' in available_providers:
                providers.append('TensorrtExecutionProvider')
                print("ğŸï¸ TensorRT Provider ì‚¬ìš© (NVIDIA GPU)")
        
        # CPUëŠ” í•­ìƒ ë°±ì—…ìœ¼ë¡œ ì¶”ê°€
        providers.append('CPUExecutionProvider')
        
        return providers
    
    def predict(self, input_data):
        """ìµœì í™”ëœ ì˜ˆì¸¡"""
        try:
            result = self.session.run([self.output_name], {self.input_name: input_data})
            return result[0]
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None

# --- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ í•¨ìˆ˜ ---
def benchmark_model(model, test_data, num_runs=100):
    """ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹"""
    print(f"ğŸƒ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì‹œì‘ ({num_runs}íšŒ ì‹¤í–‰)...")
    
    # ì›Œë°ì—…
    for _ in range(10):
        model.predict(test_data)
    
    # ì‹¤ì œ ë²¤ì¹˜ë§ˆí‚¹
    start_time = time.time()
    for _ in range(num_runs):
        model.predict(test_data)
    end_time = time.time()
    
    avg_time = (end_time - start_time) / num_runs * 1000  # ms
    fps = 1 / (avg_time / 1000)
    
    print(f"   âš¡ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.2f}ms")
    print(f"   ğŸ¯ ì´ˆë‹¹ í”„ë ˆì„: {fps:.1f} FPS")
    
    return avg_time, fps

# --- ë¹„ë™ê¸° ì˜ˆì¸¡ í´ë˜ìŠ¤ ---
class AsyncPredictor:
    def __init__(self, model):
        self.model = model
        self.input_queue = queue.Queue(maxsize=2)
        self.output_queue = queue.Queue(maxsize=2)
        self.prediction_thread = threading.Thread(target=self._prediction_worker)
        self.prediction_thread.daemon = True
        self.prediction_thread.start()
        self.last_prediction = None
    
    def _prediction_worker(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì˜ˆì¸¡ ì‘ì—…ì"""
        while True:
            try:
                input_data = self.input_queue.get(timeout=0.1)
                result = self.model.predict(input_data)
                
                # ê²°ê³¼ íê°€ ê°€ë“ ì°¬ ê²½ìš° ì´ì „ ê²°ê³¼ ì œê±°
                if self.output_queue.full():
                    try:
                        self.output_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                self.output_queue.put(result)
                self.input_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ ë¹„ë™ê¸° ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
    
    def predict_async(self, input_data):
        """ë¹„ë™ê¸° ì˜ˆì¸¡ ìš”ì²­"""
        # ì…ë ¥ íê°€ ê°€ë“ ì°¬ ê²½ìš° ì´ì „ ìš”ì²­ ì œê±°
        if self.input_queue.full():
            try:
                self.input_queue.get_nowait()
            except queue.Empty:
                pass
        
        try:
            self.input_queue.put_nowait(input_data)
        except queue.Full:
            pass
    
    def get_prediction(self):
        """ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            result = self.output_queue.get_nowait()
            self.last_prediction = result
            return result
        except queue.Empty:
            return self.last_prediction

# --- ëª¨ë¸ ì´ˆê¸°í™” í•¨ìˆ˜ ---
def initialize_optimized_model():
    """ìµœì í™”ëœ ëª¨ë¸ ì´ˆê¸°í™”"""
    print("ğŸš€ ìµœì í™”ëœ ONNX ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")
    
    # 1. ì›ë³¸ ONNX ëª¨ë¸ í™•ì¸
    if not os.path.exists(ONNX_MODEL_PATH):
        print(f"âŒ ì›ë³¸ ONNX ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {ONNX_MODEL_PATH}")
        print("ğŸ’¡ ë¨¼ì € convert_h5_to_onnx.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ ë³€í™˜í•˜ì„¸ìš”.")
        return None, None
    
    # 2. ìµœì í™”ëœ ëª¨ë¸ ë¡œë“œ ì‹œë„ (ìš°ì„ ìˆœìœ„ëŒ€ë¡œ)
    models_to_try = [
        (ONNX_QUANTIZED_PATH, "ë™ì  ì–‘ìí™” ONNX"),
        (ONNX_MODEL_PATH, "ê¸°ë³¸ ONNX")
    ]
    
    for model_path, description in models_to_try:
        if os.path.exists(model_path):
            try:
                # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
                use_gpu = len([p for p in ort.get_available_providers() 
                              if p in ['CUDAExecutionProvider', 'DmlExecutionProvider', 'OpenVINOExecutionProvider']]) > 0
                
                model = OptimizedONNXModel(
                    model_path, 
                    optimization_level="all",
                    use_gpu=use_gpu
                )
                
                print(f"âœ… {description} ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                return model, description
                
            except Exception as e:
                print(f"âŒ {description} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
    
    # 4. ë°±ì—…ìœ¼ë¡œ H5 ëª¨ë¸ ì‹œë„
    try:
        import tensorflow as tf
        from tensorflow import keras
        h5_model_path = get_backup_model_path()
        if h5_model_path and os.path.exists(h5_model_path):
            model = keras.models.load_model(h5_model_path)
            print(f"âœ… ë°±ì—… H5 ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {h5_model_path}")
            return model, "H5 ë°±ì—…"
        else:
            print("âŒ ë°±ì—… H5 ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ ë°±ì—… H5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return None, None

# --- Ollama Gemma3 í•¨ìˆ˜ ---
# í´ë˜ìŠ¤ ì´ë¦„ (í•œê¸€ â†’ ì˜ì–´ ë³€í™˜ìš©, ë˜ëŠ” UI í‘œê¸°ìš©)
class_names_kr = [
    'ê¸°ì €ì„¸í¬ì•”',
    'í‘œí”¼ë‚­ì¢…',
    'í˜ˆê´€ì¢…',
    'ë¹„ë¦½ì¢…',
    'ì •ìƒí”¼ë¶€',
    'í¸í‰ì„¸í¬ì•”',
    'ì‚¬ë§ˆê·€'
]

def get_solution_from_gemma(disease_name):
    """
    ë¡œì»¬ Ollamaì˜ Gemma3 ëª¨ë¸ì—ê²Œ í”¼ë¶€ ì§ˆí™˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ê°€ì´ë“œ ìš”ì²­.
    ì‘ë‹µì€ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ 5ë‹¨ê³„ë¡œ ìš”ì•½ë˜ë©°, 200ì ë‚´ì™¸ë¡œ ì œí•œë¨.
    """

    prompt = f"""
ë‹¹ì‹ ì€ í”¼ë¶€ ê±´ê°• ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ í”¼ë¶€ ì§ˆí™˜ì— ëŒ€í•´ 200ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì•ˆë‚´í•´ì£¼ì„¸ìš”.

í”¼ë¶€ ì§ˆí™˜ëª…: {disease_name}

ì•„ë˜ í˜•ì‹ì— ë”°ë¼ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”:

1. ì§ˆí™˜ ì„¤ëª…: ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ë‹¨íˆ
2. ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­: ì‘ê¸‰ì„± ì—¬ë¶€ í¬í•¨
3. ê°€ì • ê´€ë¦¬ ë°©ë²•: ì†ì‰½ê²Œ ì‹¤ì²œ ê°€ëŠ¥í•œ íŒ
4. ì „ë¬¸ ì¹˜ë£Œ ë°©ë²•: ë³‘ì›ì—ì„œ ë°›ì„ ìˆ˜ ìˆëŠ” ì¹˜ë£Œ
5. ì£¼ì˜ì‚¬í•­: ì¬ë°œ, ê°ì—¼, ìê°€ ì¹˜ë£Œ ê²½ê³  ë“±

ê° í•­ëª©ì€ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”.
ë‹µë³€ì€ 200ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """.strip()

    print(f"\n[{OLLAMA_MODEL} ëª¨ë¸ì—ê²Œ ì¡°ì–¸ì„ ìš”ì²­í•©ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.]")

    try:
        response = ollama.chat(
            model=OLLAMA_MODEL,
            messages=[{'role': 'user', 'content': prompt}]
        )
        return response['message']['content'].strip()

    except Exception as e:
        return f"[ì˜¤ë¥˜] Ollama ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\nOllama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."

# --- ë©”ì¸ ë¡œì§ ---
def main():
    print("ìµœì í™”ëœ ONNX ê¸°ë°˜ í”¼ë¶€ ì§ˆí™˜ ì§„ë‹¨ ì‹œìŠ¤í…œ")
    print("=" * 55)
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print(f"ğŸ’» CPU ì½”ì–´: {psutil.cpu_count(logical=False)} ë¬¼ë¦¬ / {psutil.cpu_count(logical=True)} ë…¼ë¦¬")
    print(f"ğŸ§  ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬: {psutil.virtual_memory().available / (1024**3):.1f} GB")
    print(f"âš¡ ì‚¬ìš© ê°€ëŠ¥í•œ ONNX Providers: {ort.get_available_providers()}")
    print("=" * 55)
    
    # ìº¡ì²˜ í´ë” ìƒì„±
    if not os.path.exists(CAPTURE_FOLDER):
        os.makedirs(CAPTURE_FOLDER)
    
    # ìµœì í™”ëœ ëª¨ë¸ ì´ˆê¸°í™”
    model, model_type = initialize_optimized_model()
    if model is None:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {model_type}")
    
    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ (ONNX ëª¨ë¸ì˜ ê²½ìš°)
    if model_type and ("ONNX" in model_type or "ìµœì í™”" in model_type):
        test_data = np.random.random((1, 96, 96, 3)).astype(np.float32)
        avg_time, fps = benchmark_model(model, test_data)
        
        # ë¹„ë™ê¸° ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
        async_predictor = AsyncPredictor(model)
        use_async = True
        print("ğŸ”„ ë¹„ë™ê¸° ì˜ˆì¸¡ ëª¨ë“œ í™œì„±í™”")
    else:
        use_async = False
        print("â³ ë™ê¸° ì˜ˆì¸¡ ëª¨ë“œ ì‚¬ìš©")
    
    # í°íŠ¸ ì„¤ì • (OSë³„ ëŒ€ì‘)
    font_path = get_system_font_path()
    try:
        if font_path and os.path.exists(font_path):
            font = ImageFont.truetype(font_path, 20)
            small_font = ImageFont.truetype(font_path, 14)
            print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
        else:
            font = ImageFont.load_default()
            small_font = ImageFont.load_default()
            print("âš ï¸ ì‹œìŠ¤í…œ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
    except IOError:
        font = ImageFont.load_default()
        small_font = ImageFont.load_default()
        print("âš ï¸ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")

    # ì¹´ë©”ë¼ ì„¤ì • (ì—¬ëŸ¬ ì¸ë±ìŠ¤ ì‹œë„)
    cap = None
    camera_indices = [0, 1, 2]  # ë¦¬ëˆ…ìŠ¤ì—ì„œëŠ” ë³´í†µ 0, ìœˆë„ìš°ì—ì„œëŠ” 1ì´ ì£¼ë¡œ ì‚¬ìš©ë¨
    
    for idx in camera_indices:
        cap = cv2.VideoCapture(idx)
        if cap.isOpened():
            print(f"âœ… ì¹´ë©”ë¼ {idx}ë²ˆ ì—°ê²° ì„±ê³µ")
            break
        cap.release()
    
    if cap is None or not cap.isOpened():
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ë³´ì„¸ìš”:")
        print("   - ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€")
        print("   - ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš© ì¤‘ì¸ì§€")
        print("   - ì¹´ë©”ë¼ ê¶Œí•œì´ ìˆëŠ”ì§€")
        return

    # ì¹´ë©”ë¼ í•´ìƒë„ ìµœì í™”
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    cap.set(cv2.CAP_PROP_FPS, CAMERA_FPS)

    print("ğŸ“· ì¹´ë©”ë¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("í™”ë©´ì„ ë³´ë©° ì§„ë‹¨í•  ë¶€ìœ„ë¥¼ ì¤‘ì•™ì— ìœ„ì¹˜ì‹œí‚¤ì„¸ìš”.")
    print("í‚¤ë³´ë“œ 'c'ë¥¼ ëˆ„ë¥´ë©´ 5ì´ˆê°„ ì—°ì†ìœ¼ë¡œ ì´¬ì˜í•˜ì—¬ ì§„ë‹¨í•©ë‹ˆë‹¤.")
    print("í‚¤ë³´ë“œ 'q'ë¥¼ ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    print("í‚¤ë³´ë“œ 'b'ë¥¼ ëˆ„ë¥´ë©´ ë²¤ì¹˜ë§ˆí‚¹ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

    # ì„±ëŠ¥ ì¸¡ì • ë³€ìˆ˜
    frame_count = 0
    fps_start_time = time.time()
    current_fps = 0.0 # FPS ê°’ì„ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™”
    last_display_update_time = time.time() # ë§ˆì§€ë§‰ ë””ìŠ¤í”Œë ˆì´ ì—…ë°ì´íŠ¸ ì‹œê°„
    current_display_label = ""

    # ì˜ˆì¸¡ ìŠ¤ë¬´ë”©ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    recent_predictions = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("ì˜¤ë¥˜: ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        # ì¤‘ì•™ 1:1 ì˜ì—­ crop
        h, w, _ = frame.shape
        min_dim = min(h, w)
        start_x = (w - min_dim) // 2
        start_y = (h - min_dim) // 2
        crop_frame = frame[start_y:start_y+min_dim, start_x:start_x+min_dim]

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_array = cv2.resize(crop_frame, (96, 96))
        img_array = np.expand_dims(img_array, axis=0)
        img_array = img_array.astype(np.float32) / 255.0

        # ì˜ˆì¸¡ ìˆ˜í–‰
        if use_async:
            # ë¹„ë™ê¸° ì˜ˆì¸¡
            async_predictor.predict_async(img_array)
            predictions = async_predictor.get_prediction()
            
            if predictions is not None:
                current_predicted_class_idx = np.argmax(predictions[0])
                current_confidence = predictions[0][current_predicted_class_idx]
            else:
                current_predicted_class_idx = 0
                current_confidence = 0.0
        else:
            # ë™ê¸° ì˜ˆì¸¡
            if model_type and ("ONNX" in model_type or "ìµœì í™”" in model_type):
                predictions = model.predict(img_array)
                if predictions is not None:
                    current_predicted_class_idx = np.argmax(predictions[0])
                    current_confidence = predictions[0][current_predicted_class_idx]
                else:
                    current_predicted_class_idx = 0
                    current_confidence = 0.0
            else:
                predictions = model.predict(img_array, verbose=0)
                current_predicted_class_idx = np.argmax(predictions[0])
                current_confidence = predictions[0][current_predicted_class_idx]

        # ì˜ˆì¸¡ ê²°ê³¼ ìŠ¤ë¬´ë”©
        recent_predictions.append((current_predicted_class_idx, current_confidence))
        if len(recent_predictions) > PREDICTION_SMOOTHING_WINDOW_SIZE:
            recent_predictions.pop(0) # ê°€ì¥ ì˜¤ë˜ëœ ì˜ˆì¸¡ ì œê±°

        # ìŠ¤ë¬´ë”©ëœ ì˜ˆì¸¡ ê²°ê³¼ ê³„ì‚°
        if recent_predictions:
            # ê° í´ë˜ìŠ¤ë³„ë¡œ ë“±ì¥ íšŸìˆ˜ ê³„ì‚°
            class_counts = {}
            for idx, _ in recent_predictions:
                class_counts[idx] = class_counts.get(idx, 0) + 1
            
            # ê°€ì¥ ë§ì´ ë“±ì¥í•œ í´ë˜ìŠ¤ ì„ íƒ
            smoothed_predicted_class_idx = max(class_counts, key=class_counts.get)
            
            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
            smoothed_confidence_sum = sum([conf for idx, conf in recent_predictions if idx == smoothed_predicted_class_idx])
            smoothed_confidence_count = class_counts[smoothed_predicted_class_idx]
            smoothed_confidence = smoothed_confidence_sum / smoothed_confidence_count
        else:
            smoothed_predicted_class_idx = 0
            smoothed_confidence = 0.0

        # í™”ë©´ í‘œì‹œ ì—…ë°ì´íŠ¸ ì£¼ê¸° ì œì–´
        current_time = time.time()
        if (current_time - last_display_update_time) * 1000 >= DISPLAY_UPDATE_INTERVAL_MS:
            current_display_label = f"{class_names_kr[smoothed_predicted_class_idx]} ({smoothed_confidence*100:.1f}%)"
            last_display_update_time = current_time

        # FPS ê³„ì‚°
        frame_count += 1
        if frame_count % 30 == 0:
            fps_end_time = time.time()
            current_fps = 30 / (fps_end_time - fps_start_time)
            fps_start_time = fps_end_time

        # í™”ë©´ì— í‘œì‹œ
        img_pil = Image.fromarray(cv2.cvtColor(crop_frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        
        # ë©”ì¸ ì •ë³´
        draw.text((10, 10), f"ğŸ”¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ({model_type}):", font=font, fill=(0, 255, 0))
        draw.text((10, 35), current_display_label, font=font, fill=(0, 255, 0))
        
        # ì„±ëŠ¥ ì •ë³´ (FPSëŠ” í•­ìƒ í‘œì‹œ)
        draw.text((10, 65), f"âš¡ FPS: {current_fps:.1f}", font=small_font, fill=(255, 255, 0))
        
        # ì‚¬ìš© ì¤‘ì¸ Provider ì •ë³´ (ONNX ëª¨ë¸ì˜ ê²½ìš°)
        if hasattr(model, 'session'):
            provider_info = model.session.get_providers()[0]
            draw.text((10, 85), f"ğŸ’» Provider: {provider_info.replace('ExecutionProvider', '')}", font=small_font, fill=(255, 255, 0))
        
        display_frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        cv2.imshow('ìµœì í™”ëœ ONNX í”¼ë¶€ ì§„ë‹¨', display_frame)

        key = cv2.waitKey(1) & 0xFF

        # 'b' í‚¤ë¡œ ë²¤ì¹˜ë§ˆí‚¹ ì‹¤í–‰
        if key == ord('b') and ("ONNX" in model_type or "ìµœì í™”" in model_type):
            print("\n" + "="*50)
            print("ğŸƒ ì‹¤ì‹œê°„ ë²¤ì¹˜ë§ˆí‚¹ ì‹¤í–‰")
            print("="*50)
            avg_time, fps = benchmark_model(model, img_array)

        # 'c' í‚¤ë¡œ ì§„ë‹¨ ì‹¤í–‰
        elif key == ord('c'):
            # í™”ë©´ì„ ê²€ê²Œ ë§Œë“¤ê³  "ì˜ì‚¬ì˜ ë‹µë³€ ì¤€ë¹„ì¤‘..." ë©”ì‹œì§€ í‘œì‹œ
            black_screen = np.zeros_like(display_frame)
            
            # Pillowë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ê°€
            img_pil_black = Image.fromarray(cv2.cvtColor(black_screen, cv2.COLOR_BGR2RGB))
            draw_black = ImageDraw.Draw(img_pil_black)
            
            text = "ì˜ì‚¬ì˜ ë‹µë³€ ì¤€ë¹„ì¤‘..."
            
            # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
            try:
                # Pillow 10.0.0 ì´ìƒ
                text_bbox = draw_black.textbbox((0, 0), text, font=font)
                text_width = text_bbox[2] - text_bbox[0]
                text_height = text_bbox[3] - text_bbox[1]
            except AttributeError:
                # ì´ì „ ë²„ì „ì˜ Pillow
                text_width, text_height = draw_black.textsize(text, font=font)

            text_x = (black_screen.shape[1] - text_width) // 2
            text_y = (black_screen.shape[0] - text_height) // 2
            
            draw_black.text((text_x, text_y), text, font=font, fill=(255, 255, 255))
            
            # OpenCV í˜•ì‹ìœ¼ë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
            black_screen_with_text = cv2.cvtColor(np.array(img_pil_black), cv2.COLOR_RGB2BGR)
            cv2.imshow('ìµœì í™”ëœ ONNX í”¼ë¶€ ì§„ë‹¨', black_screen_with_text)
            cv2.waitKey(1) # í™”ë©´ì„ ì¦‰ì‹œ ì—…ë°ì´íŠ¸

            # ì§„ë‹¨ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
            print("\n" + "="*40)
            print(f"ì§„ë‹¨ì„ ì‹œì‘í•©ë‹ˆë‹¤. {CAPTURE_COUNT}ì´ˆ ë™ì•ˆ {CAPTURE_COUNT}ë²ˆ ì´¬ì˜í•©ë‹ˆë‹¤.")
            print("="*40)
            
            captured_classes = []
            
            for i in range(CAPTURE_COUNT):
                time.sleep(CAPTURE_INTERVAL)
                
                # í˜„ì¬ í”„ë ˆì„ìœ¼ë¡œ ì˜ˆì¸¡
                if "ONNX" in model_type or "ìµœì í™”" in model_type:
                    current_predictions = model.predict(img_array)
                    if current_predictions is not None:
                        current_predicted_idx = np.argmax(current_predictions[0])
                    else:
                        current_predicted_idx = 0
                else:
                    current_predictions = model.predict(img_array, verbose=0)
                    current_predicted_idx = np.argmax(current_predictions[0])
                
                predicted_name = class_names_kr[current_predicted_idx]
                captured_classes.append(predicted_name)
                
                # ìº¡ì²˜ ì´ë¯¸ì§€ ì €ì¥
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                capture_path = os.path.join(CAPTURE_FOLDER, f"capture_{timestamp}_{i+1}.png")
                cv2.imwrite(capture_path, crop_frame)
                
                print(f"ì´¬ì˜ {i+1}/5... ì˜ˆì¸¡: {predicted_name}")

            # ìµœì¢… ì§„ë‹¨
            print("\n" + "-"*40)
            if len(set(captured_classes)) == 1:
                final_diagnosis = captured_classes[0]
                print(f"ìµœì¢… ì§„ë‹¨ ê²°ê³¼: **{final_diagnosis}**")
                print(f"ì‚¬ìš© ëª¨ë¸: {model_type}")
                print("-"*40)
                
                # Gemma3 í•´ê²°ì±… ìš”ì²­
                solution = get_solution_from_gemma(final_diagnosis)
                print("\n[Ollama Gemma3ì˜ ê±´ê°• ì¡°ì–¸]")
                print(solution)
                print("\n(ì£¼ì˜: ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ì •í™•í•œ ì§„ë‹¨ê³¼ ì¹˜ë£Œë¥¼ ìœ„í•´ ë°˜ë“œì‹œ ì „ë¬¸ ì˜ë£Œê¸°ê´€ì„ ë°©ë¬¸í•˜ì„¸ìš”.)")
                
            else:
                print("ì§„ë‹¨ ì‹¤íŒ¨: ì˜ˆì¸¡ ê²°ê³¼ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print(f"ì§€ë‚œ {CAPTURE_COUNT}ë²ˆì˜ ì˜ˆì¸¡: {captured_classes}")
            
            print("="*40)
            print("\në‹¤ì‹œ ì§„ë‹¨í•˜ë ¤ë©´ 'c'ë¥¼, ë²¤ì¹˜ë§ˆí‚¹ì€ 'b'ë¥¼, ì¢…ë£Œí•˜ë ¤ë©´ 'q'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")

        # 'q' í‚¤ë¡œ ì¢…ë£Œ
        elif key == ord('q'):
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main() 