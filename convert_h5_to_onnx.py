import tensorflow as tf
from tensorflow import keras
import tf2onnx
import onnx
import numpy as np
import os
import shutil
# ONNX ì–‘ìí™”ë¥¼ ìœ„í•œ ì¶”ê°€ import
try:
    from onnxruntime.quantization import quantize_static, quantize_dynamic, CalibrationDataReader, QuantType
    ONNX_QUANTIZATION_AVAILABLE = True
except ImportError:
    ONNX_QUANTIZATION_AVAILABLE = False
    print("ê²½ê³ : onnxruntime.quantizationì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install onnxruntime' ì„¤ì¹˜ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")

def convert_h5_to_onnx(h5_model_path, onnx_output_path):
    """
    H5 ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    print("=" * 60)
    print("H5 ëª¨ë¸ â†’ ONNX ë³€í™˜ ì‹œì‘")
    print("=" * 60)
    
    # 1. H5 ëª¨ë¸ ë¡œë“œ
    print(f"1. H5 ëª¨ë¸ ë¡œë“œ: {h5_model_path}")
    try:
        model = keras.models.load_model(h5_model_path)
        print(f"   [ì„±ê³µ] ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        print(f"   [ì •ë³´] ëª¨ë¸ êµ¬ì¡°: {model.input_shape} -> {model.output_shape}")
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    # 2. ONNX ë³€í™˜
    print("2. ONNX ë³€í™˜ ì¤‘...")
    temp_saved_model_path = "./temp_saved_model"
    
    try:
        onnx_model = None
        
        # ë°©ë²• 1: ì§ì ‘ Keras ëª¨ë¸ì—ì„œ ONNX ë³€í™˜ ì‹œë„
        try:
            print("   - ë°©ë²• 1: ì§ì ‘ Keras â†’ ONNX ë³€í™˜ ì‹œë„...")
            
            # ëª¨ë¸ ì¤€ë¹„
            dummy_input = tf.zeros((1, 96, 96, 3), dtype=tf.float32)
            model(dummy_input)  # ëª¨ë¸ í˜¸ì¶œí•˜ì—¬ ê·¸ë˜í”„ ë¹Œë“œ
            
            # ì…ë ¥ ì„œëª… ì„¤ì •
            input_signature = [tf.TensorSpec(shape=[None, 96, 96, 3], dtype=tf.float32)]
            
            # ONNX ë³€í™˜
            onnx_model, _ = tf2onnx.convert.from_keras(
                model, 
                input_signature=input_signature,
                opset=11
            )
            print("   - ë°©ë²• 1 ì„±ê³µ: ì§ì ‘ ë³€í™˜ ì™„ë£Œ")
            
        except Exception as e1:
            print(f"   - ë°©ë²• 1 ì‹¤íŒ¨: {e1}")
            
            # ë°©ë²• 2: SavedModel ê²½ìœ  ë³€í™˜ ì‹œë„
            try:
                print("   - ë°©ë²• 2: SavedModel ê²½ìœ  ë³€í™˜ ì‹œë„...")
                
                # ëª¨ë¸ì— call ë©”ì„œë“œ ëª…ì‹œì  ì •ì˜
                @tf.function
                def model_func(x):
                    return model(x)
                
                # êµ¬ì²´ì ì¸ ì…ë ¥ìœ¼ë¡œ íŠ¸ë ˆì´ìŠ¤
                concrete_func = model_func.get_concrete_function(
                    tf.TensorSpec(shape=[1, 96, 96, 3], dtype=tf.float32)
                )
                
                # SavedModelë¡œ ì €ì¥
                tf.saved_model.save(model, temp_saved_model_path, signatures=concrete_func)
                print("   - SavedModel ë³€í™˜ ì™„ë£Œ")
                
                # SavedModelì„ ONNXë¡œ ë³€í™˜
                onnx_model, _ = tf2onnx.convert.from_saved_model(temp_saved_model_path)
                print("   - ë°©ë²• 2 ì„±ê³µ: SavedModel ê²½ìœ  ë³€í™˜ ì™„ë£Œ")
                
            except Exception as e2:
                print(f"   - ë°©ë²• 2 ì‹¤íŒ¨: {e2}")
                
                # ë°©ë²• 3: ëª¨ë¸ ì¬êµ¬ì„± í›„ ë³€í™˜ ì‹œë„
                try:
                    print("   - ë°©ë²• 3: ëª¨ë¸ ì¬êµ¬ì„± í›„ ë³€í™˜ ì‹œë„...")
                    
                    # ëª¨ë¸ êµ¬ì¡° ë¶„ì„
                    input_shape = model.input_shape[1:]  # (96, 96, 3)
                    
                    # ìƒˆë¡œìš´ ì…ë ¥ ë ˆì´ì–´ ìƒì„±
                    new_input = tf.keras.layers.Input(shape=input_shape, name='input')
                    
                    # ê¸°ì¡´ ëª¨ë¸ì˜ ë ˆì´ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©
                    x = new_input
                    for i, layer in enumerate(model.layers):
                        # ë ˆì´ì–´ ì´ë¦„ ì„¤ì •
                        layer_name = f"{layer.__class__.__name__}_{i}"
                        
                        # ë ˆì´ì–´ ë³µì‚¬ ë° ì ìš©
                        if hasattr(layer, 'get_config'):
                            layer_config = layer.get_config()
                            layer_config['name'] = layer_name
                            
                            # ë ˆì´ì–´ ì¬ìƒì„±
                            new_layer = layer.__class__.from_config(layer_config)
                            new_layer.set_weights(layer.get_weights())
                            x = new_layer(x)
                        else:
                            # ì„¤ì •ì´ ì—†ëŠ” ë ˆì´ì–´ì˜ ê²½ìš° ì§ì ‘ ì ìš©
                            x = layer(x)
                    
                    # ìƒˆë¡œìš´ í•¨ìˆ˜í˜• ëª¨ë¸ ìƒì„±
                    functional_model = tf.keras.Model(inputs=new_input, outputs=x, name='functional_model')
                    
                    print("   - ëª¨ë¸ ì¬êµ¬ì„± ì™„ë£Œ")
                    
                    # ì¬êµ¬ì„±ëœ ëª¨ë¸ë¡œ ONNX ë³€í™˜
                    input_signature = [tf.TensorSpec(shape=[None] + list(input_shape), dtype=tf.float32)]
                    onnx_model, _ = tf2onnx.convert.from_keras(
                        functional_model,
                        input_signature=input_signature,
                        opset=11
                    )
                    print("   - ë°©ë²• 3 ì„±ê³µ: ëª¨ë¸ ì¬êµ¬ì„± í›„ ë³€í™˜ ì™„ë£Œ")
                    
                except Exception as e3:
                    print(f"   - ë°©ë²• 3 ì‹¤íŒ¨: {e3}")
                    
                    # ë°©ë²• 4: ë‹¨ìˆœ í´ë¡  ë°©ë²•
                    try:
                        print("   - ë°©ë²• 4: ë‹¨ìˆœ í´ë¡  ë°©ë²• ì‹œë„...")
                        
                        # ëª¨ë¸ í´ë¡  ìƒì„±
                        cloned_model = tf.keras.models.clone_model(model)
                        cloned_model.set_weights(model.get_weights())
                        
                        # ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ ë¹Œë“œ
                        cloned_model.build((None, 96, 96, 3))
                        
                        # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ í˜¸ì¶œ
                        dummy_input = tf.random.normal((1, 96, 96, 3))
                        _ = cloned_model(dummy_input)
                        
                        # ì…ë ¥/ì¶œë ¥ ì´ë¦„ ëª…ì‹œì  ì„¤ì •
                        cloned_model.input_names = ['input']
                        cloned_model.output_names = ['output']
                        
                        # ONNX ë³€í™˜
                        input_signature = [tf.TensorSpec(shape=[None, 96, 96, 3], dtype=tf.float32, name='input')]
                        onnx_model, _ = tf2onnx.convert.from_keras(
                            cloned_model,
                            input_signature=input_signature,
                            opset=11
                        )
                        print("   - ë°©ë²• 4 ì„±ê³µ: ë‹¨ìˆœ í´ë¡  ë°©ë²• ì™„ë£Œ")
                        
                    except Exception as e4:
                        print(f"   - ë°©ë²• 4 ì‹¤íŒ¨: {e4}")
                        raise Exception(f"ëª¨ë“  ë³€í™˜ ë°©ë²• ì‹¤íŒ¨. ë°©ë²•1: {e1}, ë°©ë²•2: {e2}, ë°©ë²•3: {e3}, ë°©ë²•4: {e4}")
        
        if onnx_model is None:
            raise Exception("ONNX ëª¨ë¸ ë³€í™˜ ì‹¤íŒ¨")

        # ONNX ëª¨ë¸ íŒŒì¼ë¡œ ì €ì¥
        with open(onnx_output_path, "wb") as f:
            f.write(onnx_model.SerializeToString())
        
        print(f"   [ì„±ê³µ] ONNX ëª¨ë¸ ìƒì„± ì„±ê³µ: {onnx_output_path}")
        
        # ëª¨ë¸ í¬ê¸° ë¹„êµ
        original_size = os.path.getsize(h5_model_path) / (1024 * 1024)  # MB
        onnx_size = os.path.getsize(onnx_output_path) / (1024 * 1024)  # MB
        print(f"   [ì •ë³´] í¬ê¸° ë¹„êµ: {original_size:.2f}MB -> {onnx_size:.2f}MB")
        
        # ì„ì‹œ SavedModel í´ë” ì‚­ì œ
        if os.path.exists(temp_saved_model_path):
            shutil.rmtree(temp_saved_model_path)
            print("   - ì„ì‹œ SavedModel í´ë” ì‚­ì œ ì™„ë£Œ")
        
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] ONNX ë³€í™˜ ì‹¤íŒ¨: {e}")
        # ì„ì‹œ SavedModel í´ë” ì‚­ì œ (ì‹¤íŒ¨ ì‹œì—ë„)
        if os.path.exists(temp_saved_model_path):
            shutil.rmtree(temp_saved_model_path)
            print("   - ì„ì‹œ SavedModel í´ë” ì‚­ì œ ì™„ë£Œ")
        return False
    
    # 3. ONNX ëª¨ë¸ ê²€ì¦
    print("3. ONNX ëª¨ë¸ ê²€ì¦")
    try:
        onnx_model = onnx.load(onnx_output_path)
        onnx.checker.check_model(onnx_model)
        print("   [ì„±ê³µ] ONNX ëª¨ë¸ ê²€ì¦ ì„±ê³µ")
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] ONNX ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False
    
    print("=" * 60)
    print("[ì„±ê³µ] ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“ ONNX ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {onnx_output_path}")
    print("=" * 60)
    
    return True

class SkinModelCalibrationDataReader(CalibrationDataReader):
    """
    í”¼ë¶€ ì§ˆí™˜ ì§„ë‹¨ ëª¨ë¸ì„ ìœ„í•œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¦¬ë”
    """
    def __init__(self, model_input_shape=(96, 96, 3), num_samples=100, input_name='input'):
        self.model_input_shape = model_input_shape
        self.num_samples = num_samples
        self.current_index = 0
        self.input_name = input_name
        
    def get_next(self):
        if self.current_index >= self.num_samples:
            return None
            
        # 96x96x3 í¬ê¸°ì˜ ëœë¤ ì´ë¯¸ì§€ ìƒì„± (0-1 ë²”ìœ„ë¡œ ì •ê·œí™”)
        input_data = np.random.random((1, *self.model_input_shape)).astype(np.float32)
        self.current_index += 1
        
        return {self.input_name: input_data}

def create_quantized_onnx_dynamic(onnx_model_path, quantized_onnx_path):
    """
    ONNX ëª¨ë¸ì„ ë™ì  ì–‘ìí™”(Dynamic Quantization)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ê°€ì¥ ë¹ ë¥´ê³  ê°„ë‹¨í•œ ë°©ë²•ì´ì§€ë§Œ ì •í™•ë„ê°€ ì•½ê°„ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    print("=" * 60)
    print("ONNX ëª¨ë¸ â†’ ë™ì  ì–‘ìí™” ONNX ë³€í™˜ ì‹œì‘")
    print("=" * 60)
    
    if not ONNX_QUANTIZATION_AVAILABLE:
        print("   [ì‹¤íŒ¨] onnxruntime.quantizationì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        print(f"1. ì›ë³¸ ONNX ëª¨ë¸ ë¡œë“œ: {onnx_model_path}")
        
        # ë™ì  ì–‘ìí™” ì‹¤í–‰
        print("2. ë™ì  ì–‘ìí™” ì‹¤í–‰ ì¤‘...")
        quantize_dynamic(
            model_input=onnx_model_path,
            model_output=quantized_onnx_path,
            weight_type=QuantType.QUInt8  # 8ë¹„íŠ¸ unsigned int ì‚¬ìš©
        )
        
        print(f"   [ì„±ê³µ] ë™ì  ì–‘ìí™” ONNX ëª¨ë¸ ìƒì„±: {quantized_onnx_path}")
        
        # íŒŒì¼ í¬ê¸° ë¹„êµ
        original_size = os.path.getsize(onnx_model_path) / (1024 * 1024)  # MB
        quantized_size = os.path.getsize(quantized_onnx_path) / (1024 * 1024)  # MB
        print(f"   [ì •ë³´] í¬ê¸° ë¹„êµ: {original_size:.2f}MB -> {quantized_size:.2f}MB ({quantized_size/original_size*100:.1f}%)")
        
        return True
        
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] ë™ì  ì–‘ìí™” ì‹¤íŒ¨: {e}")
        return False

def create_quantized_onnx_static(onnx_model_path, quantized_onnx_path):
    """
    ONNX ëª¨ë¸ì„ ì •ì  ì–‘ìí™”(Static Quantization)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ì–‘ìí™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("=" * 60)
    print("ONNX ëª¨ë¸ â†’ ì •ì  ì–‘ìí™” ONNX ë³€í™˜ ì‹œì‘")
    print("=" * 60)
    
    if not ONNX_QUANTIZATION_AVAILABLE:
        print("   [ì‹¤íŒ¨] onnxruntime.quantizationì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        print(f"1. ì›ë³¸ ONNX ëª¨ë¸ ë¡œë“œ: {onnx_model_path}")
        
        # ONNX ëª¨ë¸ ì •ë³´ í™•ì¸
        onnx_model = onnx.load(onnx_model_path)
        input_name = onnx_model.graph.input[0].name
        print(f"   [ì •ë³´] ëª¨ë¸ ì…ë ¥ ì´ë¦„: {input_name}")
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¦¬ë” ìƒì„±
        print("2. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        calibration_data_reader = SkinModelCalibrationDataReader(input_name=input_name)
        
        # ì •ì  ì–‘ìí™” ì‹¤í–‰
        print("3. ì •ì  ì–‘ìí™” ì‹¤í–‰ ì¤‘...")
        quantize_static(
            model_input=onnx_model_path,
            model_output=quantized_onnx_path,
            calibration_data_reader=calibration_data_reader,
            quant_format=QuantType.QUInt8  # 8ë¹„íŠ¸ unsigned int ì‚¬ìš©
        )
        
        print(f"   [ì„±ê³µ] ì •ì  ì–‘ìí™” ONNX ëª¨ë¸ ìƒì„±: {quantized_onnx_path}")
        
        # íŒŒì¼ í¬ê¸° ë¹„êµ
        original_size = os.path.getsize(onnx_model_path) / (1024 * 1024)  # MB
        quantized_size = os.path.getsize(quantized_onnx_path) / (1024 * 1024)  # MB
        print(f"   [ì •ë³´] í¬ê¸° ë¹„êµ: {original_size:.2f}MB -> {quantized_size:.2f}MB ({quantized_size/original_size*100:.1f}%)")
        
        return True
        
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] ì •ì  ì–‘ìí™” ì‹¤íŒ¨: {e}")
        return False

def create_quantized_onnx(h5_model_path, tflite_output_path):
    """
    H5 ëª¨ë¸ì„ 8ë¹„íŠ¸ ì–‘ìí™”ëœ TFLiteë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    print("=" * 60)
    print("H5 ëª¨ë¸ â†’ 8ë¹„íŠ¸ ì–‘ìí™” TFLite ë³€í™˜ ì‹œì‘")
    print("=" * 60)
    
    # 1. H5 ëª¨ë¸ ë¡œë“œ
    print(f"1. H5 ëª¨ë¸ ë¡œë“œ: {h5_model_path}")
    try:
        model = keras.models.load_model(h5_model_path)
        print(f"   [ì„±ê³µ] ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    # 2. ì–‘ìí™”ë¥¼ ìœ„í•œ ëŒ€í‘œ ë°ì´í„°ì…‹ ìƒì„±
    print("2. ì–‘ìí™”ë¥¼ ìœ„í•œ ëŒ€í‘œ ë°ì´í„°ì…‹ ìƒì„±")
    def representative_dataset():
        for _ in range(100):
            # 96x96x3 í¬ê¸°ì˜ ëœë¤ ì´ë¯¸ì§€ ìƒì„± (0-1 ë²”ìœ„ë¡œ ì •ê·œí™”)
            data = np.random.random((1, 96, 96, 3)).astype(np.float32)
            yield [data]
    
    # 3. TensorFlow Lite ë³€í™˜ê¸° ì„¤ì • (8ë¹„íŠ¸ ì–‘ìí™”)
    print("3. TensorFlow Lite ë³€í™˜ê¸° ì„¤ì • (8ë¹„íŠ¸ ì–‘ìí™”)")
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = representative_dataset
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    
    # 4. TFLite ëª¨ë¸ ë³€í™˜
    print("4. TFLite ëª¨ë¸ ë³€í™˜ ì¤‘...")
    try:
        tflite_model = converter.convert()
        
        # TFLite íŒŒì¼ ì €ì¥
        with open(tflite_output_path, 'wb') as f:
            f.write(tflite_model)
        print(f"   [ì„±ê³µ] TFLite ëª¨ë¸ ìƒì„± ì„±ê³µ: {tflite_output_path}")
        
        # íŒŒì¼ í¬ê¸° ë¹„êµ
        original_size = os.path.getsize(h5_model_path) / (1024 * 1024)  # MB
        tflite_size = os.path.getsize(tflite_output_path) / (1024 * 1024)  # MB
        print(f"   [ì •ë³´] í¬ê¸° ë¹„êµ: {original_size:.2f}MB -> {tflite_size:.2f}MB ({tflite_size/original_size*100:.1f}%)")
        
    except Exception as e:
        print(f"   [ì‹¤íŒ¨] TFLite ë³€í™˜ ì‹¤íŒ¨: {e}")
        return False
    
    print("=" * 60)
    print("[ì„±ê³µ] 8ë¹„íŠ¸ ì–‘ìí™” TFLite ë³€í™˜ ì™„ë£Œ!")
    print(f"[ì €ì¥] TFLite ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {tflite_output_path}")
    print("=" * 60)
    
    return True

if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì •
    h5_model_path = "./model/skin_model.h5"
    onnx_output_path = "./model/skin_model.onnx"
    onnx_quantized_dynamic_path = "./model/skin_model_quantized_dynamic.onnx"
    onnx_quantized_static_path = "./model/skin_model_quantized_static.onnx"
    tflite_output_path = "./model/skin_model_quantized.tflite"
    
    # model í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    model_dir = "./model"
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
        print(f"ğŸ“ ì¶œë ¥ í´ë” ìƒì„±: {model_dir}")
    
    print("[ì‹œì‘] í”¼ë¶€ ì§ˆí™˜ ì§„ë‹¨ ëª¨ë¸ ë³€í™˜ ì‹œì‘!")
    print("=" * 60)
    
    # 1. H5 â†’ ONNX ë³€í™˜
    print("[ì‘ì—… 1] H5 â†’ ONNX ë³€í™˜")
    onnx_success = convert_h5_to_onnx(h5_model_path, onnx_output_path)
    
    print("\n" + "=" * 60)
    
    # 2. ONNX â†’ ë™ì  ì–‘ìí™” ONNX ë³€í™˜
    onnx_dynamic_success = False
    if onnx_success:
        print("[ì‘ì—… 2] ONNX â†’ ë™ì  ì–‘ìí™” ONNX ë³€í™˜")
        onnx_dynamic_success = create_quantized_onnx_dynamic(onnx_output_path, onnx_quantized_dynamic_path)
    else:
        print("[ì‘ì—… 2] ONNX â†’ ë™ì  ì–‘ìí™” ONNX ë³€í™˜ (ê±´ë„ˆëœ€: ONNX ë³€í™˜ ì‹¤íŒ¨)")
    
    print("\n" + "=" * 60)
    
    # 3. ONNX â†’ ì •ì  ì–‘ìí™” ONNX ë³€í™˜
    onnx_static_success = False
    if onnx_success:
        print("[ì‘ì—… 3] ONNX â†’ ì •ì  ì–‘ìí™” ONNX ë³€í™˜")
        onnx_static_success = create_quantized_onnx_static(onnx_output_path, onnx_quantized_static_path)
    else:
        print("[ì‘ì—… 3] ONNX â†’ ì •ì  ì–‘ìí™” ONNX ë³€í™˜ (ê±´ë„ˆëœ€: ONNX ë³€í™˜ ì‹¤íŒ¨)")
    
    print("\n" + "=" * 60)
    
    # 4. H5 â†’ 8ë¹„íŠ¸ ì–‘ìí™” TFLite ë³€í™˜
    print("[ì‘ì—… 4] H5 â†’ 8ë¹„íŠ¸ ì–‘ìí™” TFLite ë³€í™˜")
    tflite_success = create_quantized_onnx(h5_model_path, tflite_output_path)
    
    print("\n" + "=" * 60)
    print("[ìš”ì•½] ë³€í™˜ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    if onnx_success:
        print("[ì„±ê³µ] ONNX ë³€í™˜ ì„±ê³µ")
    else:
        print("[ì‹¤íŒ¨] ONNX ë³€í™˜ ì‹¤íŒ¨")
    
    if onnx_dynamic_success:
        print("[ì„±ê³µ] ONNX ë™ì  ì–‘ìí™” ë³€í™˜ ì„±ê³µ")
    else:
        print("[ì‹¤íŒ¨] ONNX ë™ì  ì–‘ìí™” ë³€í™˜ ì‹¤íŒ¨")
    
    if onnx_static_success:
        print("[ì„±ê³µ] ONNX ì •ì  ì–‘ìí™” ë³€í™˜ ì„±ê³µ")
    else:
        print("[ì‹¤íŒ¨] ONNX ì •ì  ì–‘ìí™” ë³€í™˜ ì‹¤íŒ¨")
    
    if tflite_success:
        print("[ì„±ê³µ] 8ë¹„íŠ¸ ì–‘ìí™” TFLite ë³€í™˜ ì„±ê³µ")
    else:
        print("[ì‹¤íŒ¨] 8ë¹„íŠ¸ ì–‘ìí™” TFLite ë³€í™˜ ì‹¤íŒ¨")
    
    success_count = sum([onnx_success, onnx_dynamic_success, onnx_static_success, tflite_success])
    
    if success_count > 0:
        print(f"[ê²°ê³¼] {success_count}/4 ë³€í™˜ì´ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
        print("[ì•ˆë‚´] ì´ì œ ì¹´ë©”ë¼ ì§„ë‹¨ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("[ëª¨ë¸ íŒŒì¼]")
        if onnx_success:
            print(f"  - ì›ë³¸ ONNX: {onnx_output_path}")
        if onnx_dynamic_success:
            print(f"  - ë™ì  ì–‘ìí™” ONNX: {onnx_quantized_dynamic_path}")
        if onnx_static_success:
            print(f"  - ì •ì  ì–‘ìí™” ONNX: {onnx_quantized_static_path}")
        if tflite_success:
            print(f"  - ì–‘ìí™” TFLite: {tflite_output_path}")
    else:
        print("[ê²°ê³¼] ëª¨ë“  ë³€í™˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("[ì•ˆë‚´] í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:")
        print("   pip install tf2onnx onnx onnxruntime tensorflow") 